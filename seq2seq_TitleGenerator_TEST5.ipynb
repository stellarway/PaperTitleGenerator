{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "B23DdhejooW4",
    "outputId": "4521c869-115d-42a7-9d08-506d0a8fefe9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20fc123d370>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext import data\n",
    "import math\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qG9zq1-mooXN"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jsTD-H-ooXX"
   },
   "outputs": [],
   "source": [
    "path ='./data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OdmM-rXcooXg"
   },
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DByY_-qxooXj",
    "outputId": "6c809647-356c-416e-9d89-7edbd2febdcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "spm.SentencePieceTrainer.Train('--input={}/train.dat --model_prefix=m --vocab_size=50000'.format(path))\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('m.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BV1xAqE_ooXr"
   },
   "outputs": [],
   "source": [
    "tokenizer = lambda x: sp.EncodeAsPieces(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07BsJg07ooXz"
   },
   "outputs": [],
   "source": [
    "PAD, EOS, BOS = 1,2,3\n",
    "fix_length=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVfypUsaooX7"
   },
   "outputs": [],
   "source": [
    "SRC = data.Field(sequential=True, # False면 tokenization이 적용되지 않는다.\n",
    "            use_vocab=True, # False면 data는 이미 numerical한 상태여야 한다.\n",
    "            fix_length=fix_length,\n",
    "            preprocessing=None,\n",
    "            lower=True,\n",
    "            tokenize=tokenizer,\n",
    "        #                  include_lengths=True, # list의 길이까지 튜플 형식으로 반환\n",
    "#             batch_first=True, # Whether to produce tensors with the batch dimension first\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XmL9kQ8DooYB"
   },
   "outputs": [],
   "source": [
    "TGT = data.Field(sequential=True,\n",
    "            use_vocab=True,\n",
    "            fix_length=fix_length,\n",
    "            preprocessing=None,\n",
    "            lower=True,\n",
    "            tokenize=tokenizer,\n",
    "#                  include_lengths=True,\n",
    "#             batch_first=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMFuvnvcooYH"
   },
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = data.TabularDataset.splits(path=path+'/',\n",
    "                                                        train='train.dat',\n",
    "                                                        validation='val.dat',\n",
    "                                                        test='test.dat',\n",
    "                                                        format='tsv',\n",
    "                                                        fields=[('tgt', TGT), ('src',SRC)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "zl6M4R2gooYS",
    "outputId": "a6c9aa59-20cb-4f71-c325-7d7719e915f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 35360\n",
      "Number of validation examples: 4420\n",
      "Number of testing examples: 4420\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(val_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "N8joANgPooYZ",
    "outputId": "d6fc400b-bccd-462d-af20-03d6ef543cf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tgt': ['▁fast', '▁methods', '▁for', '▁recover', 'ing', '▁sparse', '▁parameters', '▁in', '▁linear', '▁low', '▁rank', '▁models'], 'src': ['▁in', '▁this', '▁paper', ',', '▁we', '▁investigate', '▁the', '▁recovery', '▁of', '▁a', '▁sparse', '▁weight', '▁vector', '▁(', 'parameters', '▁vector', ')', '▁from', '▁a', '▁set', '▁of', '▁noisy', '▁linear', '▁combinations', '.', '▁however', ',', '▁only', '▁partial', '▁information', '▁about', '▁the', '▁matrix', '▁representing', '▁the', '▁linear', '▁combinations', '▁is', '▁available', '.', '▁assum', 'ing', '▁a', '▁low', '-', 'rank', '▁structure', '▁for', '▁the', '▁matrix', ',', '▁one', '▁natural', '▁solution', '▁would', '▁be', '▁to', '▁first', '▁apply', '▁a', '▁matrix', '▁completion', '▁on', '▁the', '▁data', ',', '▁and', '▁then', '▁to', '▁solve', '▁the', '▁resulting', '▁compressed', '▁sensing', '▁problem', '.', '▁in', '▁big', '▁data', '▁applications', '▁such', '▁as', '▁massive', '▁mimo', '▁and', '▁medical', '▁data', ',', '▁the', '▁matrix', '▁completion', '▁step', '▁impose', 's', '▁a', '▁huge', '▁computational', '▁burden', '.', '▁here', ',', '▁we', '▁propose', '▁to', '▁reduce', '▁the', '▁computational', '▁cost', '▁of', '▁the', '▁completion', '▁task', '▁by', '▁', 'ignoring', '▁the', '▁columns', '▁corresponding', '▁to', '▁zero', '▁elements', '▁in', '▁the', '▁sparse', '▁vector', '.', '▁to', '▁this', '▁end', ',', '▁we', '▁employ', '▁a', '▁technique', '▁to', '▁initially', '▁approximate', '▁the', '▁support', '▁of', '▁the', '▁sparse', '▁vector', '.', '▁we', '▁further', '▁propose', '▁to', '▁unify', '▁the', '▁partial', '▁matrix', '▁completion', '▁and', '▁sparse', '▁vector', '▁recovery', '▁into', '▁an', '▁augmented', '▁four', '-', 'step', '▁problem', '.', '▁simulation', '▁results', '▁reveal', '▁that', '▁the', '▁augmented', '▁approach', '▁achieves', '▁the', '▁best', '▁performance', ',', '▁while', '▁both', '▁proposed', '▁methods', '▁outperform', '▁the', '▁natural', '▁two', '-', 'step', '▁technique', '▁with', '▁substantially', '▁less', '▁computational', '▁requirements', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csbKFgLAooYi"
   },
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data)\n",
    "TGT.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "DunWvyxGooYp",
    "outputId": "3609bcf8-e78e-4d86-d225-0c701fdc2489"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (abstract) vocabulary: 41855\n",
      "Unique tokens in target (title) vocabulary: 17770\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (abstract) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (title) vocabulary: {len(TGT.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sr_KB9Gxv1Sm",
    "outputId": "fe336412-715b-4e38-c1b2-9bc61b6dede4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CzkuIQ3ooYx"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05OiI4_6ooY6"
   },
   "outputs": [],
   "source": [
    "# bucketiterator defines an iterator that batches examples of similar lengths together\n",
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train_data, val_data, test_data),\n",
    "     batch_size=batch_size,\n",
    "     sort_key=lambda x: data.interleave_keys(len(x.tgt), len(x.src)),\n",
    "     sort_within_batch=True,\n",
    "     device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNvy8kEsooZD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x0000020FC2B089C8>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             '▁the': 2,\n",
       "             '.': 3,\n",
       "             ',': 4,\n",
       "             '▁of': 5,\n",
       "             '-': 6,\n",
       "             '▁and': 7,\n",
       "             '▁a': 8,\n",
       "             '▁to': 9,\n",
       "             '▁in': 10,\n",
       "             '▁we': 11,\n",
       "             '▁is': 12,\n",
       "             '▁for': 13,\n",
       "             '▁that': 14,\n",
       "             '▁on': 15,\n",
       "             '▁with': 16,\n",
       "             '▁this': 17,\n",
       "             '▁(': 18,\n",
       "             '▁learning': 19,\n",
       "             '▁are': 20,\n",
       "             '▁as': 21,\n",
       "             '▁by': 22,\n",
       "             ')': 23,\n",
       "             '▁neural': 24,\n",
       "             's': 25,\n",
       "             '▁': 26,\n",
       "             '▁an': 27,\n",
       "             '▁network': 28,\n",
       "             'ing': 29,\n",
       "             '▁our': 30,\n",
       "             '▁networks': 31,\n",
       "             '▁deep': 32,\n",
       "             '▁data': 33,\n",
       "             '▁can': 34,\n",
       "             '▁from': 35,\n",
       "             '▁model': 36,\n",
       "             '▁which': 37,\n",
       "             '▁be': 38,\n",
       "             '▁method': 39,\n",
       "             '▁models': 40,\n",
       "             '▁gradient': 41,\n",
       "             '▁show': 42,\n",
       "             '▁paper': 43,\n",
       "             '▁results': 44,\n",
       "             '▁it': 45,\n",
       "             '▁using': 46,\n",
       "             '▁methods': 47,\n",
       "             '▁training': 48,\n",
       "             '▁machine': 49,\n",
       "             '▁performance': 50,\n",
       "             '▁based': 51,\n",
       "             '▁have': 52,\n",
       "             '▁proposed': 53,\n",
       "             '▁these': 54,\n",
       "             '▁such': 55,\n",
       "             '▁algorithm': 56,\n",
       "             '▁$': 57,\n",
       "             '▁problem': 58,\n",
       "             '▁approach': 59,\n",
       "             '▁or': 60,\n",
       "             '▁has': 61,\n",
       "             '▁propose': 62,\n",
       "             '▁also': 63,\n",
       "             '▁at': 64,\n",
       "             '▁two': 65,\n",
       "             '▁new': 66,\n",
       "             '▁state': 67,\n",
       "             '▁time': 68,\n",
       "             '▁used': 69,\n",
       "             '▁algorithms': 70,\n",
       "             '▁not': 71,\n",
       "             '▁different': 72,\n",
       "             '▁classification': 73,\n",
       "             '▁both': 74,\n",
       "             '▁between': 75,\n",
       "             'ed': 76,\n",
       "             '▁more': 77,\n",
       "             '▁one': 78,\n",
       "             '▁information': 79,\n",
       "             '▁large': 80,\n",
       "             '▁been': 81,\n",
       "             '▁convolutional': 82,\n",
       "             '▁function': 83,\n",
       "             '▁features': 84,\n",
       "             '▁use': 85,\n",
       "             '▁vector': 86,\n",
       "             '▁their': 87,\n",
       "             '▁work': 88,\n",
       "             '▁image': 89,\n",
       "             '▁over': 90,\n",
       "             '▁high': 91,\n",
       "             '▁its': 92,\n",
       "             'd': 93,\n",
       "             '▁tasks': 94,\n",
       "             \"'\": 95,\n",
       "             '$': 96,\n",
       "             '▁than': 97,\n",
       "             'based': 98,\n",
       "             '▁framework': 99,\n",
       "             '▁when': 100,\n",
       "             '▁well': 101,\n",
       "             '▁non': 102,\n",
       "             '▁number': 103,\n",
       "             '▁problems': 104,\n",
       "             ':': 105,\n",
       "             '▁however': 106,\n",
       "             '▁accuracy': 107,\n",
       "             '▁present': 108,\n",
       "             'of': 109,\n",
       "             '▁descent': 110,\n",
       "             '),': 111,\n",
       "             '▁analysis': 112,\n",
       "             '▁where': 113,\n",
       "             ').': 114,\n",
       "             'the': 115,\n",
       "             '▁optimization': 116,\n",
       "             '▁first': 117,\n",
       "             '▁$\\\\': 118,\n",
       "             '▁system': 119,\n",
       "             '▁demonstrate': 120,\n",
       "             '▁into': 121,\n",
       "             '▁each': 122,\n",
       "             '▁feature': 123,\n",
       "             '▁while': 124,\n",
       "             '▁task': 125,\n",
       "             '▁support': 126,\n",
       "             '▁set': 127,\n",
       "             '▁novel': 128,\n",
       "             '▁recurrent': 129,\n",
       "             'e': 130,\n",
       "             '▁experiments': 131,\n",
       "             '▁study': 132,\n",
       "             '▁only': 133,\n",
       "             '▁other': 134,\n",
       "             '▁systems': 135,\n",
       "             '▁many': 136,\n",
       "             '▁\\\\': 137,\n",
       "             '▁datasets': 138,\n",
       "             '▁real': 139,\n",
       "             '▁multi': 140,\n",
       "             'art': 141,\n",
       "             '▁but': 142,\n",
       "             '/': 143,\n",
       "             '▁space': 144,\n",
       "             '▁learn': 145,\n",
       "             '{': 146,\n",
       "             '▁applications': 147,\n",
       "             '▁linear': 148,\n",
       "             'n': 149,\n",
       "             '▁all': 150,\n",
       "             '▁most': 151,\n",
       "             '▁input': 152,\n",
       "             '▁structure': 153,\n",
       "             '▁provide': 154,\n",
       "             '▁functions': 155,\n",
       "             '▁approaches': 156,\n",
       "             '▁stochastic': 157,\n",
       "             '▁dataset': 158,\n",
       "             '▁how': 159,\n",
       "             '▁images': 160,\n",
       "             '▁then': 161,\n",
       "             '▁architecture': 162,\n",
       "             '▁parameters': 163,\n",
       "             '▁techniques': 164,\n",
       "             '▁trained': 165,\n",
       "             '▁some': 166,\n",
       "             '▁recent': 167,\n",
       "             '▁representation': 168,\n",
       "             '▁prediction': 169,\n",
       "             '▁existing': 170,\n",
       "             '▁convergence': 171,\n",
       "             '▁several': 172,\n",
       "             '▁process': 173,\n",
       "             '▁low': 174,\n",
       "             '▁order': 175,\n",
       "             '▁under': 176,\n",
       "             '▁better': 177,\n",
       "             '▁through': 178,\n",
       "             '▁representations': 179,\n",
       "             '▁efficient': 180,\n",
       "             '▁graph': 181,\n",
       "             '▁random': 182,\n",
       "             '▁multiple': 183,\n",
       "             '▁recognition': 184,\n",
       "             '▁complex': 185,\n",
       "             '▁given': 186,\n",
       "             '▁local': 187,\n",
       "             '▁distribution': 188,\n",
       "             '▁loss': 189,\n",
       "             '▁detection': 190,\n",
       "             '▁gradients': 191,\n",
       "             '▁matrix': 192,\n",
       "             'g': 193,\n",
       "             '▁compared': 194,\n",
       "             '▁without': 195,\n",
       "             '▁memory': 196,\n",
       "             '▁field': 197,\n",
       "             '▁simple': 198,\n",
       "             '▁rate': 199,\n",
       "             '▁general': 200,\n",
       "             '▁single': 201,\n",
       "             'y': 202,\n",
       "             '▁any': 203,\n",
       "             '▁error': 204,\n",
       "             '▁properties': 205,\n",
       "             'to': 206,\n",
       "             '▁they': 207,\n",
       "             'ly': 208,\n",
       "             '\\\\': 209,\n",
       "             '▁introduce': 210,\n",
       "             '▁computational': 211,\n",
       "             '▁knowledge': 212,\n",
       "             '▁design': 213,\n",
       "             'dimensional': 214,\n",
       "             ';': 215,\n",
       "             '▁three': 216,\n",
       "             '▁small': 217,\n",
       "             '▁further': 218,\n",
       "             '▁various': 219,\n",
       "             't': 220,\n",
       "             '▁experimental': 221,\n",
       "             '▁standard': 222,\n",
       "             '▁particular': 223,\n",
       "             '▁case': 224,\n",
       "             '▁very': 225,\n",
       "             '▁learned': 226,\n",
       "             '▁architectures': 227,\n",
       "             '▁layers': 228,\n",
       "             '▁optimal': 229,\n",
       "             '▁human': 230,\n",
       "             '▁may': 231,\n",
       "             '▁important': 232,\n",
       "             '▁class': 233,\n",
       "             '▁layer': 234,\n",
       "             '▁including': 235,\n",
       "             '▁theory': 236,\n",
       "             '▁due': 237,\n",
       "             '▁vectors': 238,\n",
       "             '▁find': 239,\n",
       "             'i': 240,\n",
       "             '▁same': 241,\n",
       "             '▁applied': 242,\n",
       "             '▁terms': 243,\n",
       "             '▁achieve': 244,\n",
       "             'x': 245,\n",
       "             '▁recently': 246,\n",
       "             'k': 247,\n",
       "             '▁i': 248,\n",
       "             '▁research': 249,\n",
       "             '▁long': 250,\n",
       "             '(': 251,\n",
       "             '▁result': 252,\n",
       "             '▁shown': 253,\n",
       "             '▁improve': 254,\n",
       "             '▁\"': 255,\n",
       "             '▁language': 256,\n",
       "             '▁sparse': 257,\n",
       "             '▁reinforcement': 258,\n",
       "             '▁domain': 259,\n",
       "             '▁dynamics': 260,\n",
       "             '▁solution': 261,\n",
       "             '▁previous': 262,\n",
       "             '▁inference': 263,\n",
       "             '▁apply': 264,\n",
       "             '▁there': 265,\n",
       "             '▁significantly': 266,\n",
       "             '▁consider': 267,\n",
       "             '▁size': 268,\n",
       "             '▁complexity': 269,\n",
       "             '▁regression': 270,\n",
       "             '▁them': 271,\n",
       "             '}': 272,\n",
       "             '▁even': 273,\n",
       "             '▁numerical': 274,\n",
       "             '▁adversarial': 275,\n",
       "             '▁control': 276,\n",
       "             '▁effective': 277,\n",
       "             '▁point': 278,\n",
       "             '▁theoretical': 279,\n",
       "             '_': 280,\n",
       "             '▁end': 281,\n",
       "             '▁noise': 282,\n",
       "             '▁was': 283,\n",
       "             'a': 284,\n",
       "             '▁train': 285,\n",
       "             '▁often': 286,\n",
       "             '▁allows': 287,\n",
       "             '▁samples': 288,\n",
       "             '▁available': 289,\n",
       "             '▁sequence': 290,\n",
       "             '▁processing': 291,\n",
       "             '▁energy': 292,\n",
       "             '▁best': 293,\n",
       "             '▁test': 294,\n",
       "             '▁natural': 295,\n",
       "             '▁examples': 296,\n",
       "             '▁kernel': 297,\n",
       "             '▁current': 298,\n",
       "             '▁technique': 299,\n",
       "             '▁so': 300,\n",
       "             '▁obtained': 301,\n",
       "             '▁prove': 302,\n",
       "             '▁up': 303,\n",
       "             '▁provides': 304,\n",
       "             '▁via': 305,\n",
       "             '▁cost': 306,\n",
       "             '\"': 307,\n",
       "             '▁power': 308,\n",
       "             '▁second': 309,\n",
       "             '▁attention': 310,\n",
       "             '▁perform': 311,\n",
       "             '▁known': 312,\n",
       "             '▁thus': 313,\n",
       "             '▁application': 314,\n",
       "             '▁here': 315,\n",
       "             '▁finally': 316,\n",
       "             '▁outperforms': 317,\n",
       "             '▁generalization': 318,\n",
       "             '▁convex': 319,\n",
       "             '▁parameter': 320,\n",
       "             '▁estimation': 321,\n",
       "             '▁significant': 322,\n",
       "             '▁able': 323,\n",
       "             '▁within': 324,\n",
       "             'al': 325,\n",
       "             'm': 326,\n",
       "             '▁will': 327,\n",
       "             '▁search': 328,\n",
       "             '▁global': 329,\n",
       "             '▁potential': 330,\n",
       "             '▁objective': 331,\n",
       "             '▁sample': 332,\n",
       "             '▁signal': 333,\n",
       "             'p': 334,\n",
       "             '▁develop': 335,\n",
       "             '▁obtain': 336,\n",
       "             '▁distributed': 337,\n",
       "             'r': 338,\n",
       "             '▁modeling': 339,\n",
       "             '▁way': 340,\n",
       "             '▁quantum': 341,\n",
       "             '▁flow': 342,\n",
       "             '▁solutions': 343,\n",
       "             'level': 344,\n",
       "             '▁about': 345,\n",
       "             '▁across': 346,\n",
       "             '▁traditional': 347,\n",
       "             '▁step': 348,\n",
       "             '▁robust': 349,\n",
       "             '▁3': 350,\n",
       "             '▁similar': 351,\n",
       "             '▁temporal': 352,\n",
       "             'j': 353,\n",
       "             '▁conditions': 354,\n",
       "             '▁efficiency': 355,\n",
       "             '▁challenging': 356,\n",
       "             '▁context': 357,\n",
       "             '▁target': 358,\n",
       "             '▁fully': 359,\n",
       "             '▁form': 360,\n",
       "             '▁predict': 361,\n",
       "             '▁weights': 362,\n",
       "             '▁embedding': 363,\n",
       "             '▁policy': 364,\n",
       "             '▁output': 365,\n",
       "             '▁machines': 366,\n",
       "             '▁supervised': 367,\n",
       "             '▁sets': 368,\n",
       "             'o': 369,\n",
       "             '▁no': 370,\n",
       "             '▁text': 371,\n",
       "             '▁called': 372,\n",
       "             '▁scheme': 373,\n",
       "             '▁points': 374,\n",
       "             '▁empirical': 375,\n",
       "             '▁approximation': 376,\n",
       "             '▁online': 377,\n",
       "             'scale': 378,\n",
       "             '▁cnn': 379,\n",
       "             '▁possible': 380,\n",
       "             '▁key': 381,\n",
       "             '▁if': 382,\n",
       "             '▁investigate': 383,\n",
       "             '▁decision': 384,\n",
       "             '▁were': 385,\n",
       "             '▁computation': 386,\n",
       "             '▁level': 387,\n",
       "             '2': 388,\n",
       "             '▁achieves': 389,\n",
       "             '▁evaluate': 390,\n",
       "             '▁object': 391,\n",
       "             '▁statistical': 392,\n",
       "             '▁setting': 393,\n",
       "             'f': 394,\n",
       "             '▁address': 395,\n",
       "             '▁finite': 396,\n",
       "             '▁visual': 397,\n",
       "             '▁during': 398,\n",
       "             '▁achieved': 399,\n",
       "             '▁higher': 400,\n",
       "             '▁segmentation': 401,\n",
       "             '▁quality': 402,\n",
       "             '▁do': 403,\n",
       "             '▁out': 404,\n",
       "             'world': 405,\n",
       "             '▁scale': 406,\n",
       "             '▁word': 407,\n",
       "             '▁range': 408,\n",
       "             '▁probability': 409,\n",
       "             '▁nonlinear': 410,\n",
       "             '▁developed': 411,\n",
       "             '▁type': 412,\n",
       "             '▁furthermore': 413,\n",
       "             '▁latent': 414,\n",
       "             '▁continuous': 415,\n",
       "             '▁effectiveness': 416,\n",
       "             '▁main': 417,\n",
       "             '▁benchmark': 418,\n",
       "             '▁spatial': 419,\n",
       "             '▁much': 420,\n",
       "             '▁generative': 421,\n",
       "             '▁behavior': 422,\n",
       "             '▁m': 423,\n",
       "             '▁d': 424,\n",
       "             '▁solve': 425,\n",
       "             '▁identify': 426,\n",
       "             '▁evaluation': 427,\n",
       "             '▁s': 428,\n",
       "             '+': 429,\n",
       "             '▁uses': 430,\n",
       "             '▁directly': 431,\n",
       "             '▁addition': 432,\n",
       "             '▁describe': 433,\n",
       "             'c': 434,\n",
       "             '▁phase': 435,\n",
       "             '▁classical': 436,\n",
       "             '▁artificial': 437,\n",
       "             '▁compare': 438,\n",
       "             '▁classifier': 439,\n",
       "             'end': 440,\n",
       "             '▁series': 441,\n",
       "             '▁short': 442,\n",
       "             '▁computer': 443,\n",
       "             '▁popular': 444,\n",
       "             '▁prior': 445,\n",
       "             '▁value': 446,\n",
       "             '▁pre': 447,\n",
       "             '▁structures': 448,\n",
       "             '▁user': 449,\n",
       "             '▁generated': 450,\n",
       "             '▁make': 451,\n",
       "             '▁those': 452,\n",
       "             '▁transfer': 453,\n",
       "             '▁specific': 454,\n",
       "             '▁few': 455,\n",
       "             'l': 456,\n",
       "             '▁found': 457,\n",
       "             '▁moreover': 458,\n",
       "             '▁allow': 459,\n",
       "             '▁need': 460,\n",
       "             'z': 461,\n",
       "             '▁good': 462,\n",
       "             '▁specifically': 463,\n",
       "             '▁computing': 464,\n",
       "             '▁limited': 465,\n",
       "             '▁common': 466,\n",
       "             '▁hidden': 467,\n",
       "             '▁n': 468,\n",
       "             '▁bayesian': 469,\n",
       "             '▁selection': 470,\n",
       "             '▁patterns': 471,\n",
       "             '▁us': 472,\n",
       "             '▁ability': 473,\n",
       "             ']': 474,\n",
       "             '▁distributions': 475,\n",
       "             '▁among': 476,\n",
       "             '▁gaussian': 477,\n",
       "             '▁values': 478,\n",
       "             '▁k': 479,\n",
       "             '▁types': 480,\n",
       "             '▁accurate': 481,\n",
       "             '▁does': 482,\n",
       "             '▁semantic': 483,\n",
       "             '▁highly': 484,\n",
       "             '▁studies': 485,\n",
       "             '[': 486,\n",
       "             '▁sampling': 487,\n",
       "             '▁regularization': 488,\n",
       "             '▁speech': 489,\n",
       "             '▁unsupervised': 490,\n",
       "             '▁lower': 491,\n",
       "             '▁strong': 492,\n",
       "             '$-': 493,\n",
       "             '▁distance': 494,\n",
       "             '▁observed': 495,\n",
       "             '▁bound': 496,\n",
       "             '▁like': 497,\n",
       "             'in': 498,\n",
       "             '▁nodes': 499,\n",
       "             '▁estimate': 500,\n",
       "             '▁source': 501,\n",
       "             '▁understanding': 502,\n",
       "             '▁fast': 503,\n",
       "             '▁dynamic': 504,\n",
       "             '▁e': 505,\n",
       "             '▁related': 506,\n",
       "             '▁clustering': 507,\n",
       "             '▁requires': 508,\n",
       "             '▁efficiently': 509,\n",
       "             '▁shows': 510,\n",
       "             '▁mean': 511,\n",
       "             '▁extensive': 512,\n",
       "             '▁fields': 513,\n",
       "             '▁challenge': 514,\n",
       "             '▁states': 515,\n",
       "             '▁still': 516,\n",
       "             '▁being': 517,\n",
       "             '▁corresponding': 518,\n",
       "             '▁require': 519,\n",
       "             '▁variables': 520,\n",
       "             '▁take': 521,\n",
       "             '▁code': 522,\n",
       "             '▁fixed': 523,\n",
       "             '▁solving': 524,\n",
       "             '▁mechanism': 525,\n",
       "             ')$': 526,\n",
       "             '▁presented': 527,\n",
       "             '▁convolution': 528,\n",
       "             'learning': 529,\n",
       "             '▁cases': 530,\n",
       "             '▁generate': 531,\n",
       "             '▁vision': 532,\n",
       "             '▁future': 533,\n",
       "             '▁analyze': 534,\n",
       "             '▁binary': 535,\n",
       "             '▁designed': 536,\n",
       "             '▁domains': 537,\n",
       "             '▁could': 538,\n",
       "             '▁strategy': 539,\n",
       "             '▁variety': 540,\n",
       "             '▁reduce': 541,\n",
       "             'time': 542,\n",
       "             'using': 543,\n",
       "             '▁example': 544,\n",
       "             '▁resulting': 545,\n",
       "             '▁bounds': 546,\n",
       "             '▁classes': 547,\n",
       "             '▁video': 548,\n",
       "             '▁improved': 549,\n",
       "             '▁focus': 550,\n",
       "             '▁derive': 551,\n",
       "             '▁discuss': 552,\n",
       "             '▁neurons': 553,\n",
       "             '▁metric': 554,\n",
       "             '▁because': 555,\n",
       "             '▁associated': 556,\n",
       "             '▁density': 557,\n",
       "             '▁speed': 558,\n",
       "             '▁constraints': 559,\n",
       "             '▁learns': 560,\n",
       "             '▁hand': 561,\n",
       "             '▁2': 562,\n",
       "             '▁certain': 563,\n",
       "             '▁adaptive': 564,\n",
       "             '▁group': 565,\n",
       "             '▁interest': 566,\n",
       "             '▁communication': 567,\n",
       "             '▁conventional': 568,\n",
       "             'term': 569,\n",
       "             '▁measure': 570,\n",
       "             '▁practical': 571,\n",
       "             '▁open': 572,\n",
       "             '▁faster': 573,\n",
       "             '▁environment': 574,\n",
       "             '▁widely': 575,\n",
       "             '▁weight': 576,\n",
       "             '▁equations': 577,\n",
       "             '▁robustness': 578,\n",
       "             '▁less': 579,\n",
       "             '▁give': 580,\n",
       "             '▁critical': 581,\n",
       "             '▁action': 582,\n",
       "             '}$': 583,\n",
       "             '▁classifiers': 584,\n",
       "             '▁approximate': 585,\n",
       "             '▁against': 586,\n",
       "             '▁wide': 587,\n",
       "             '▁predictions': 588,\n",
       "             '▁self': 589,\n",
       "             '▁since': 590,\n",
       "             '▁underlying': 591,\n",
       "             '▁rnn': 592,\n",
       "             '▁variational': 593,\n",
       "             '▁processes': 594,\n",
       "             '▁labels': 595,\n",
       "             '▁simulations': 596,\n",
       "             '▁objects': 597,\n",
       "             '▁original': 598,\n",
       "             '▁embeddings': 599,\n",
       "             '▁signals': 600,\n",
       "             '▁rates': 601,\n",
       "             '▁discrete': 602,\n",
       "             '▁dimension': 603,\n",
       "             '▁who': 604,\n",
       "             '▁equation': 605,\n",
       "             '▁challenges': 606,\n",
       "             '▁success': 607,\n",
       "             '▁therefore': 608,\n",
       "             '▁implementation': 609,\n",
       "             '▁simulation': 610,\n",
       "             '▁extract': 611,\n",
       "             '▁useful': 612,\n",
       "             'b': 613,\n",
       "             '▁sequences': 614,\n",
       "             '▁average': 615,\n",
       "             '▁respect': 616,\n",
       "             '▁inputs': 617,\n",
       "             'cnn': 618,\n",
       "             '▁explore': 619,\n",
       "             '▁synthetic': 620,\n",
       "             '▁effect': 621,\n",
       "             'like': 622,\n",
       "             '▁improvement': 623,\n",
       "             '▁generation': 624,\n",
       "             '$.': 625,\n",
       "             '▁works': 626,\n",
       "             '▁combine': 627,\n",
       "             '▁parallel': 628,\n",
       "             'order': 629,\n",
       "             '▁map': 630,\n",
       "             '▁p': 631,\n",
       "             '▁components': 632,\n",
       "             '▁derived': 633,\n",
       "             '▁either': 634,\n",
       "             '▁part': 635,\n",
       "             '▁agent': 636,\n",
       "             '▁along': 637,\n",
       "             '▁considered': 638,\n",
       "             '$,': 639,\n",
       "             '▁additional': 640,\n",
       "             '▁capture': 641,\n",
       "             '▁positive': 642,\n",
       "             '▁literature': 643,\n",
       "             '▁after': 644,\n",
       "             '▁reduction': 645,\n",
       "             '▁introduced': 646,\n",
       "             '▁outperform': 647,\n",
       "             '▁difficult': 648,\n",
       "             '▁especially': 649,\n",
       "             '▁activation': 650,\n",
       "             '▁un': 651,\n",
       "             '▁re': 652,\n",
       "             '▁procedure': 653,\n",
       "             '▁estimates': 654,\n",
       "             'se': 655,\n",
       "             '▁full': 656,\n",
       "             '▁development': 657,\n",
       "             '▁instead': 658,\n",
       "             '▁years': 659,\n",
       "             '▁sub': 660,\n",
       "             '▁similarity': 661,\n",
       "             '▁functional': 662,\n",
       "             '▁enables': 663,\n",
       "             '▁automatically': 664,\n",
       "             '▁semi': 665,\n",
       "             '▁leads': 666,\n",
       "             '▁brain': 667,\n",
       "             'h': 668,\n",
       "             '▁users': 669,\n",
       "             '▁improves': 670,\n",
       "             '▁cross': 671,\n",
       "             '▁spaces': 672,\n",
       "             'ic': 673,\n",
       "             '▁graphs': 674,\n",
       "             '▁promising': 675,\n",
       "             '▁predictive': 676,\n",
       "             '▁devices': 677,\n",
       "             '▁making': 678,\n",
       "             '▁component': 679,\n",
       "             '▁makes': 680,\n",
       "             '▁c': 681,\n",
       "             '▁term': 682,\n",
       "             '▁attacks': 683,\n",
       "             '▁suggest': 684,\n",
       "             '▁observations': 685,\n",
       "             '▁presents': 686,\n",
       "             '▁required': 687,\n",
       "             '▁f': 688,\n",
       "             '▁goal': 689,\n",
       "             '▁evolution': 690,\n",
       "             '▁question': 691,\n",
       "             '▁tensor': 692,\n",
       "             '▁amount': 693,\n",
       "             '▁hierarchical': 694,\n",
       "             '▁settings': 695,\n",
       "             '▁agents': 696,\n",
       "             '▁condition': 697,\n",
       "             '▁initial': 698,\n",
       "             '▁become': 699,\n",
       "             '▁units': 700,\n",
       "             '▁sequential': 701,\n",
       "             '▁meta': 702,\n",
       "             '▁provided': 703,\n",
       "             '▁sgd': 704,\n",
       "             '▁active': 705,\n",
       "             '▁matrices': 706,\n",
       "             '▁tools': 707,\n",
       "             '▁competitive': 708,\n",
       "             '▁effectively': 709,\n",
       "             '▁performed': 710,\n",
       "             '▁demonstrated': 711,\n",
       "             '▁node': 712,\n",
       "             '▁independent': 713,\n",
       "             '▁probabilistic': 714,\n",
       "             '▁individual': 715,\n",
       "             '▁help': 716,\n",
       "             '▁increasing': 717,\n",
       "             '▁comparison': 718,\n",
       "             '▁role': 719,\n",
       "             '▁al': 720,\n",
       "             '▁property': 721,\n",
       "             '▁depth': 722,\n",
       "             '▁maps': 723,\n",
       "             '▁smooth': 724,\n",
       "             '▁studied': 725,\n",
       "             '▁compute': 726,\n",
       "             '▁establish': 727,\n",
       "             '▁strategies': 728,\n",
       "             '▁translation': 729,\n",
       "             '▁risk': 730,\n",
       "             '▁least': 731,\n",
       "             '▁evaluated': 732,\n",
       "             '▁reconstruction': 733,\n",
       "             '▁noisy': 734,\n",
       "             '▁structured': 735,\n",
       "             '▁contrast': 736,\n",
       "             '▁made': 737,\n",
       "             '▁operations': 738,\n",
       "             '▁regions': 739,\n",
       "             '▁combination': 740,\n",
       "             '▁lstm': 741,\n",
       "             '▁uncertainty': 742,\n",
       "             '▁extend': 743,\n",
       "             '▁automatic': 744,\n",
       "             '▁construct': 745,\n",
       "             '▁typically': 746,\n",
       "             '▁defined': 747,\n",
       "             '▁relevant': 748,\n",
       "             '▁measurements': 749,\n",
       "             '▁increase': 750,\n",
       "             '▁variable': 751,\n",
       "             '▁magnetic': 752,\n",
       "             '▁powerful': 753,\n",
       "             '▁hardware': 754,\n",
       "             '▁connections': 755,\n",
       "             '▁baseline': 756,\n",
       "             '▁x': 757,\n",
       "             '▁generalized': 758,\n",
       "             '▁dimensional': 759,\n",
       "             '▁interactions': 760,\n",
       "             '▁arbitrary': 761,\n",
       "             '▁galaxies': 762,\n",
       "             '▁four': 763,\n",
       "             '▁activity': 764,\n",
       "             '▁although': 765,\n",
       "             '▁fundamental': 766,\n",
       "             '▁suitable': 767,\n",
       "             '▁tool': 768,\n",
       "             '▁exhibit': 769,\n",
       "             'rnn': 770,\n",
       "             '▁simultaneously': 771,\n",
       "             '▁spectral': 772,\n",
       "             '▁per': 773,\n",
       "             '▁effects': 774,\n",
       "             '▁motion': 775,\n",
       "             '▁cifar': 776,\n",
       "             '▁measures': 777,\n",
       "             '▁respectively': 778,\n",
       "             'or': 779,\n",
       "             '▁differential': 780,\n",
       "             '▁l': 781,\n",
       "             '▁issue': 782,\n",
       "             '▁unit': 783,\n",
       "             'linear': 784,\n",
       "             '▁importance': 785,\n",
       "             '▁maximum': 786,\n",
       "             '▁employ': 787,\n",
       "             '▁et': 788,\n",
       "             '▁sparsity': 789,\n",
       "             '▁block': 790,\n",
       "             'wards': 791,\n",
       "             '▁extraction': 792,\n",
       "             'free': 793,\n",
       "             '▁building': 794,\n",
       "             '▁physical': 795,\n",
       "             '▁previously': 796,\n",
       "             '▁residual': 797,\n",
       "             '▁stability': 798,\n",
       "             '▁label': 799,\n",
       "             '▁words': 800,\n",
       "             '▁correlation': 801,\n",
       "             '▁limit': 802,\n",
       "             '▁rely': 803,\n",
       "             '▁art': 804,\n",
       "             '▁labeled': 805,\n",
       "             '▁privacy': 806,\n",
       "             '▁larger': 807,\n",
       "             '▁environments': 808,\n",
       "             '▁ensemble': 809,\n",
       "             'layer': 810,\n",
       "             '▁connected': 811,\n",
       "             '▁computationally': 812,\n",
       "             '▁major': 813,\n",
       "             '▁constant': 814,\n",
       "             '▁r': 815,\n",
       "             '▁times': 816,\n",
       "             '▁pattern': 817,\n",
       "             'wise': 818,\n",
       "             '▁zero': 819,\n",
       "             '▁implemented': 820,\n",
       "             '▁software': 821,\n",
       "             '▁leverage': 822,\n",
       "             '▁medical': 823,\n",
       "             '▁superior': 824,\n",
       "             '▁temperature': 825,\n",
       "             'v': 826,\n",
       "             '▁aim': 827,\n",
       "             '▁unknown': 828,\n",
       "             '▁produce': 829,\n",
       "             '▁practice': 830,\n",
       "             '▁tree': 831,\n",
       "             '▁channel': 832,\n",
       "             '▁cnns': 833,\n",
       "             '▁svm': 834,\n",
       "             '▁usually': 835,\n",
       "             '▁direction': 836,\n",
       "             '▁alternative': 837,\n",
       "             '▁assumptions': 838,\n",
       "             '▁nature': 839,\n",
       "             '▁retrieval': 840,\n",
       "             '▁schemes': 841,\n",
       "             '▁t': 842,\n",
       "             '▁world': 843,\n",
       "             '▁face': 844,\n",
       "             '▁product': 845,\n",
       "             '▁scenarios': 846,\n",
       "             '▁what': 847,\n",
       "             '▁comparable': 848,\n",
       "             '▁q': 849,\n",
       "             '▁reduced': 850,\n",
       "             '▁variance': 851,\n",
       "             '▁great': 852,\n",
       "             '▁dynamical': 853,\n",
       "             '▁surface': 854,\n",
       "             '▁top': 855,\n",
       "             '▁fine': 856,\n",
       "             '▁joint': 857,\n",
       "             '▁guarantees': 858,\n",
       "             '▁interaction': 859,\n",
       "             '^': 860,\n",
       "             '▁namely': 861,\n",
       "             '▁special': 862,\n",
       "             '▁capable': 863,\n",
       "             '▁structural': 864,\n",
       "             '▁represent': 865,\n",
       "             '▁compression': 866,\n",
       "             '▁manifold': 867,\n",
       "             '▁manner': 868,\n",
       "             '▁explicit': 869,\n",
       "             '▁should': 870,\n",
       "             '▁deal': 871,\n",
       "             '▁kernels': 872,\n",
       "             '▁illustrate': 873,\n",
       "             '▁performs': 874,\n",
       "             'mathbb': 875,\n",
       "             '▁exact': 876,\n",
       "             '▁iterative': 877,\n",
       "             '▁lead': 878,\n",
       "             '▁social': 879,\n",
       "             '▁region': 880,\n",
       "             '▁build': 881,\n",
       "             '▁empirically': 882,\n",
       "             '▁successfully': 883,\n",
       "             '▁modern': 884,\n",
       "             '▁overall': 885,\n",
       "             '▁scaling': 886,\n",
       "             '▁transition': 887,\n",
       "             '▁version': 888,\n",
       "             '▁relative': 889,\n",
       "             '▁basis': 890,\n",
       "             '▁finding': 891,\n",
       "             '▁yet': 892,\n",
       "             '▁traffic': 893,\n",
       "             '▁advantages': 894,\n",
       "             '▁concept': 895,\n",
       "             '▁advantage': 896,\n",
       "             '_{': 897,\n",
       "             'convex': 898,\n",
       "             '▁rules': 899,\n",
       "             '▁utilize': 900,\n",
       "             'trained': 901,\n",
       "             '▁exist': 902,\n",
       "             '▁improvements': 903,\n",
       "             '▁factor': 904,\n",
       "             '▁mnist': 905,\n",
       "             '▁family': 906,\n",
       "             '▁shape': 907,\n",
       "             '▁precision': 908,\n",
       "             '▁rather': 909,\n",
       "             '▁conditional': 910,\n",
       "             '▁audio': 911,\n",
       "             '▁near': 912,\n",
       "             '▁changes': 913,\n",
       "             '▁relation': 914,\n",
       "             '▁select': 915,\n",
       "             '▁policies': 916,\n",
       "             '▁providing': 917,\n",
       "             '▁predicting': 918,\n",
       "             '▁steps': 919,\n",
       "             '▁cannot': 920,\n",
       "             '▁capacity': 921,\n",
       "             '▁minimization': 922,\n",
       "             '▁particularly': 923,\n",
       "             '▁mapping': 924,\n",
       "             '▁generalize': 925,\n",
       "             '▁easily': 926,\n",
       "             '▁idea': 927,\n",
       "             '▁iteration': 928,\n",
       "             '▁optimize': 929,\n",
       "             '▁hybrid': 930,\n",
       "             '▁rule': 931,\n",
       "             '▁account': 932,\n",
       "             '▁boundary': 933,\n",
       "             '▁exploit': 934,\n",
       "             '▁assumption': 935,\n",
       "             '▁consistent': 936,\n",
       "             '▁depend': 937,\n",
       "             '▁testing': 938,\n",
       "             '▁imaging': 939,\n",
       "             '▁identification': 940,\n",
       "             '▁combined': 941,\n",
       "             '▁--': 942,\n",
       "             '▁batch': 943,\n",
       "             '▁encoder': 944,\n",
       "             '▁response': 945,\n",
       "             '▁advances': 946,\n",
       "             '▁benchmarks': 947,\n",
       "             '▁coordinate': 948,\n",
       "             '▁negative': 949,\n",
       "             'svm': 950,\n",
       "             '▁area': 951,\n",
       "             '1': 952,\n",
       "             'supervised': 953,\n",
       "             '▁another': 954,\n",
       "             '▁rank': 955,\n",
       "             '▁consists': 956,\n",
       "             '▁metrics': 957,\n",
       "             '▁h': 958,\n",
       "             '▁inverse': 959,\n",
       "             '▁tested': 960,\n",
       "             '▁generating': 961,\n",
       "             '▁length': 962,\n",
       "             '▁supports': 963,\n",
       "             '▁enable': 964,\n",
       "             '▁operator': 965,\n",
       "             '▁matching': 966,\n",
       "             '▁velocity': 967,\n",
       "             '▁characteristics': 968,\n",
       "             '▁errors': 969,\n",
       "             '▁proposes': 970,\n",
       "             '▁statistics': 971,\n",
       "             'q': 972,\n",
       "             '▁sensing': 973,\n",
       "             '▁degree': 974,\n",
       "             '▁sufficient': 975,\n",
       "             'uch': 976,\n",
       "             '▁evidence': 977,\n",
       "             '▁include': 978,\n",
       "             '▁presence': 979,\n",
       "             '▁article': 980,\n",
       "             '▁geometric': 981,\n",
       "             '▁impact': 982,\n",
       "             '▁means': 983,\n",
       "             'driven': 984,\n",
       "             '▁whether': 985,\n",
       "             '▁formulation': 986,\n",
       "             '▁showing': 987,\n",
       "             '▁stable': 988,\n",
       "             '▁implement': 989,\n",
       "             '▁ones': 990,\n",
       "             '▁direct': 991,\n",
       "             '▁expected': 992,\n",
       "             '▁access': 993,\n",
       "             '▁discriminative': 994,\n",
       "             '▁strongly': 995,\n",
       "             'w': 996,\n",
       "             'u': 997,\n",
       "             '▁frequency': 998,\n",
       "             '▁recovery': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlVA4QLZooZO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x0000020FB19D21C8>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             '-': 2,\n",
       "             '▁for': 3,\n",
       "             '▁of': 4,\n",
       "             '▁learning': 5,\n",
       "             '▁and': 6,\n",
       "             '▁neural': 7,\n",
       "             '▁deep': 8,\n",
       "             '▁a': 9,\n",
       "             '▁in': 10,\n",
       "             ':': 11,\n",
       "             '▁networks': 12,\n",
       "             '▁the': 13,\n",
       "             '▁with': 14,\n",
       "             's': 15,\n",
       "             'ing': 16,\n",
       "             '▁': 17,\n",
       "             '▁on': 18,\n",
       "             '▁network': 19,\n",
       "             '▁gradient': 20,\n",
       "             '▁to': 21,\n",
       "             '▁convolutional': 22,\n",
       "             'ed': 23,\n",
       "             '▁machine': 24,\n",
       "             '▁using': 25,\n",
       "             '▁multi': 26,\n",
       "             '▁recurrent': 27,\n",
       "             '▁classification': 28,\n",
       "             '▁data': 29,\n",
       "             '▁from': 30,\n",
       "             ',': 31,\n",
       "             'using': 32,\n",
       "             '▁via': 33,\n",
       "             'based': 34,\n",
       "             '▁an': 35,\n",
       "             '▁model': 36,\n",
       "             '▁models': 37,\n",
       "             '▁descent': 38,\n",
       "             '▁based': 39,\n",
       "             '▁optimization': 40,\n",
       "             '▁by': 41,\n",
       "             '▁reinforcement': 42,\n",
       "             '▁analysis': 43,\n",
       "             '▁stochastic': 44,\n",
       "             '▁image': 45,\n",
       "             '▁approach': 46,\n",
       "             '▁detection': 47,\n",
       "             '▁recognition': 48,\n",
       "             'd': 49,\n",
       "             '▁vector': 50,\n",
       "             '▁prediction': 51,\n",
       "             '▁non': 52,\n",
       "             '▁training': 53,\n",
       "             '▁method': 54,\n",
       "             '▁efficient': 55,\n",
       "             '▁systems': 56,\n",
       "             '▁graph': 57,\n",
       "             'al': 58,\n",
       "             '▁methods': 59,\n",
       "             'y': 60,\n",
       "             '▁sparse': 61,\n",
       "             '▁time': 62,\n",
       "             '▁adversarial': 63,\n",
       "             '▁algorithm': 64,\n",
       "             '▁support': 65,\n",
       "             '▁large': 66,\n",
       "             '▁algorithms': 67,\n",
       "             '▁distributed': 68,\n",
       "             '▁p': 69,\n",
       "             '▁estimation': 70,\n",
       "             '▁gradients': 71,\n",
       "             '▁linear': 72,\n",
       "             '▁random': 73,\n",
       "             'e': 74,\n",
       "             '▁representation': 75,\n",
       "             '▁feature': 76,\n",
       "             '▁framework': 77,\n",
       "             '▁high': 78,\n",
       "             '▁adaptive': 79,\n",
       "             '▁bayesian': 80,\n",
       "             '▁representations': 81,\n",
       "             'j': 82,\n",
       "             '▁quantum': 83,\n",
       "             '▁online': 84,\n",
       "             '▁fast': 85,\n",
       "             '▁modeling': 86,\n",
       "             '▁dynamics': 87,\n",
       "             '▁c': 88,\n",
       "             '▁machines': 89,\n",
       "             '▁generative': 90,\n",
       "             ')': 91,\n",
       "             '▁robust': 92,\n",
       "             '▁s': 93,\n",
       "             '▁through': 94,\n",
       "             'to': 95,\n",
       "             '▁inference': 96,\n",
       "             '▁information': 97,\n",
       "             '▁regression': 98,\n",
       "             '▁theory': 99,\n",
       "             '▁as': 100,\n",
       "             '▁applications': 101,\n",
       "             '▁toward': 102,\n",
       "             '▁functions': 103,\n",
       "             '▁segmentation': 104,\n",
       "             '▁language': 105,\n",
       "             '▁system': 106,\n",
       "             '▁control': 107,\n",
       "             '▁problems': 108,\n",
       "             '▁convergence': 109,\n",
       "             'scale': 110,\n",
       "             '▁(': 111,\n",
       "             '?': 112,\n",
       "             '▁flow': 113,\n",
       "             '▁structure': 114,\n",
       "             '▁kernel': 115,\n",
       "             \"'\": 116,\n",
       "             '▁low': 117,\n",
       "             '▁transfer': 118,\n",
       "             '▁memory': 119,\n",
       "             '▁application': 120,\n",
       "             '▁matrix': 121,\n",
       "             '▁improv': 122,\n",
       "             '▁search': 123,\n",
       "             '▁local': 124,\n",
       "             '▁self': 125,\n",
       "             'ic': 126,\n",
       "             '▁attention': 127,\n",
       "             'dimensional': 128,\n",
       "             '▁unsupervised': 129,\n",
       "             '▁study': 130,\n",
       "             '▁variational': 131,\n",
       "             '▁text': 132,\n",
       "             '▁optimal': 133,\n",
       "             '▁features': 134,\n",
       "             '▁semi': 135,\n",
       "             '▁at': 136,\n",
       "             'ly': 137,\n",
       "             '▁dynamic': 138,\n",
       "             't': 139,\n",
       "             '▁two': 140,\n",
       "             '▁h': 141,\n",
       "             '▁over': 142,\n",
       "             '▁selection': 143,\n",
       "             '▁regularization': 144,\n",
       "             '▁visual': 145,\n",
       "             '▁multiple': 146,\n",
       "             '▁nonlinear': 147,\n",
       "             '▁sequence': 148,\n",
       "             '▁human': 149,\n",
       "             '▁images': 150,\n",
       "             '▁$': 151,\n",
       "             '▁predict': 152,\n",
       "             '▁complex': 153,\n",
       "             '▁embedding': 154,\n",
       "             '▁space': 155,\n",
       "             '▁convex': 156,\n",
       "             '▁active': 157,\n",
       "             '▁d': 158,\n",
       "             '▁hierarchical': 159,\n",
       "             '▁3': 160,\n",
       "             '▁automatic': 161,\n",
       "             'learning': 162,\n",
       "             '▁energy': 163,\n",
       "             '▁function': 164,\n",
       "             '▁generation': 165,\n",
       "             '▁state': 166,\n",
       "             '▁architecture': 167,\n",
       "             '▁speech': 168,\n",
       "             '▁clustering': 169,\n",
       "             '▁new': 170,\n",
       "             '▁survey': 171,\n",
       "             'end': 172,\n",
       "             '.': 173,\n",
       "             '▁end': 174,\n",
       "             '▁embeddings': 175,\n",
       "             '▁generalization': 176,\n",
       "             '▁knowledge': 177,\n",
       "             '▁semantic': 178,\n",
       "             '▁generalized': 179,\n",
       "             '▁object': 180,\n",
       "             '▁field': 181,\n",
       "             '▁performance': 182,\n",
       "             '▁design': 183,\n",
       "             '▁equations': 184,\n",
       "             '▁un': 185,\n",
       "             '▁global': 186,\n",
       "             '▁long': 187,\n",
       "             'supervised': 188,\n",
       "             '▁structured': 189,\n",
       "             '▁supervised': 190,\n",
       "             '▁approximation': 191,\n",
       "             '▁artificial': 192,\n",
       "             '▁series': 193,\n",
       "             '▁under': 194,\n",
       "             '▁real': 195,\n",
       "             '▁problem': 196,\n",
       "             '▁gaussian': 197,\n",
       "             '▁statistical': 198,\n",
       "             '▁policy': 199,\n",
       "             '▁understanding': 200,\n",
       "             '▁tensor': 201,\n",
       "             '▁meta': 202,\n",
       "             '▁e': 203,\n",
       "             'time': 204,\n",
       "             '▁hybrid': 205,\n",
       "             '▁one': 206,\n",
       "             '▁scale': 207,\n",
       "             '▁l': 208,\n",
       "             '▁word': 209,\n",
       "             'level': 210,\n",
       "             '▁temporal': 211,\n",
       "             '▁translation': 212,\n",
       "             '▁re': 213,\n",
       "             'z': 214,\n",
       "             '▁loss': 215,\n",
       "             '▁evolution': 216,\n",
       "             'robabilistic': 217,\n",
       "             '▁properties': 218,\n",
       "             '▁video': 219,\n",
       "             'free': 220,\n",
       "             '▁i': 221,\n",
       "             '▁domain': 222,\n",
       "             '▁processes': 223,\n",
       "             '▁phase': 224,\n",
       "             '▁sampling': 225,\n",
       "             'able': 226,\n",
       "             '▁graphs': 227,\n",
       "             '▁computing': 228,\n",
       "             '▁equation': 229,\n",
       "             '▁identification': 230,\n",
       "             '▁is': 231,\n",
       "             '▁power': 232,\n",
       "             '▁finite': 233,\n",
       "             '▁its': 234,\n",
       "             '▁natural': 235,\n",
       "             'aware': 236,\n",
       "             '▁metric': 237,\n",
       "             '▁point': 238,\n",
       "             '▁processing': 239,\n",
       "             'n': 240,\n",
       "             '2': 241,\n",
       "             '▁bound': 242,\n",
       "             '▁forecasting': 243,\n",
       "             '▁action': 244,\n",
       "             '▁case': 245,\n",
       "             '▁fields': 246,\n",
       "             '▁learn': 247,\n",
       "             '▁m': 248,\n",
       "             '▁spaces': 249,\n",
       "             '▁architectures': 250,\n",
       "             '▁continuous': 251,\n",
       "             '▁decision': 252,\n",
       "             '▁evaluation': 253,\n",
       "             '▁latent': 254,\n",
       "             'es': 255,\n",
       "             '▁between': 256,\n",
       "             '▁fully': 257,\n",
       "             '/': 258,\n",
       "             'task': 259,\n",
       "             '▁reconstruction': 260,\n",
       "             '▁residual': 261,\n",
       "             '▁single': 262,\n",
       "             '▁techniques': 263,\n",
       "             '▁short': 264,\n",
       "             'net': 265,\n",
       "             'a': 266,\n",
       "             '▁compression': 267,\n",
       "             '▁signal': 268,\n",
       "             '▁coordinate': 269,\n",
       "             '▁noise': 270,\n",
       "             '▁parallel': 271,\n",
       "             '▁rate': 272,\n",
       "             '▁spectral': 273,\n",
       "             '▁discrete': 274,\n",
       "             '▁general': 275,\n",
       "             '▁behavior': 276,\n",
       "             '▁binary': 277,\n",
       "             '▁order': 278,\n",
       "             '▁differential': 279,\n",
       "             '▁reduction': 280,\n",
       "             '▁spatial': 281,\n",
       "             'oint': 282,\n",
       "             '▁scalable': 283,\n",
       "             '▁spiking': 284,\n",
       "             '▁k': 285,\n",
       "             'order': 286,\n",
       "             'wise': 287,\n",
       "             '▁distribution': 288,\n",
       "             '▁automated': 289,\n",
       "             '▁functional': 290,\n",
       "             '▁recovery': 291,\n",
       "             '▁sensing': 292,\n",
       "             'shot': 293,\n",
       "             '▁super': 294,\n",
       "             '▁retrieval': 295,\n",
       "             '▁brain': 296,\n",
       "             '▁conditional': 297,\n",
       "             '▁cross': 298,\n",
       "             '▁communication': 299,\n",
       "             '▁v': 300,\n",
       "             'ation': 301,\n",
       "             'on': 302,\n",
       "             'p': 303,\n",
       "             'term': 304,\n",
       "             '▁complexity': 305,\n",
       "             '▁context': 306,\n",
       "             '▁convolution': 307,\n",
       "             '▁extraction': 308,\n",
       "             '▁relation': 309,\n",
       "             '▁attacks': 310,\n",
       "             '▁magnetic': 311,\n",
       "             '▁sequential': 312,\n",
       "             '▁galaxies': 313,\n",
       "             '▁density': 314,\n",
       "             '▁inverse': 315,\n",
       "             '▁novel': 316,\n",
       "             '▁robustness': 317,\n",
       "             '▁group': 318,\n",
       "             '▁w': 319,\n",
       "             '▁comparison': 320,\n",
       "             '▁how': 321,\n",
       "             '▁approximate': 322,\n",
       "             '▁ensemble': 323,\n",
       "             '▁without': 324,\n",
       "             '▁imaging': 325,\n",
       "             '▁mean': 326,\n",
       "             '▁b': 327,\n",
       "             '▁dynamical': 328,\n",
       "             '▁simple': 329,\n",
       "             '▁solutions': 330,\n",
       "             '▁stability': 331,\n",
       "             '▁structures': 332,\n",
       "             '▁perspective': 333,\n",
       "             '▁predictive': 334,\n",
       "             '▁t': 335,\n",
       "             '▁task': 336,\n",
       "             '▁accelerated': 337,\n",
       "             '▁empirical': 338,\n",
       "             '▁flows': 339,\n",
       "             '▁r': 340,\n",
       "             '▁de': 341,\n",
       "             '▁music': 342,\n",
       "             '▁audio': 343,\n",
       "             '▁tracking': 344,\n",
       "             '▁computation': 345,\n",
       "             '▁minimization': 346,\n",
       "             '▁small': 347,\n",
       "             '▁adaptation': 348,\n",
       "             '▁dual': 349,\n",
       "             '▁f': 350,\n",
       "             '▁factorization': 351,\n",
       "             'gradient': 352,\n",
       "             'linear': 353,\n",
       "             '▁error': 354,\n",
       "             '▁layer': 355,\n",
       "             '▁proximal': 356,\n",
       "             '▁type': 357,\n",
       "             'temporal': 358,\n",
       "             '▁lstm': 359,\n",
       "             '▁process': 360,\n",
       "             '▁risk': 361,\n",
       "             '▁uncertainty': 362,\n",
       "             '▁interpretable': 363,\n",
       "             '▁limit': 364,\n",
       "             '▁tree': 365,\n",
       "             'efficient': 366,\n",
       "             '▁coding': 367,\n",
       "             '▁first': 368,\n",
       "             '▁privacy': 369,\n",
       "             '▁universal': 370,\n",
       "             '▁activity': 371,\n",
       "             'driven': 372,\n",
       "             '▁effective': 373,\n",
       "             '▁motion': 374,\n",
       "             '▁social': 375,\n",
       "             'ary': 376,\n",
       "             '▁are': 377,\n",
       "             '▁iterative': 378,\n",
       "             '▁parameter': 379,\n",
       "             '▁manifold': 380,\n",
       "             'convex': 381,\n",
       "             '▁nonconvex': 382,\n",
       "             'c': 383,\n",
       "             '▁solving': 384,\n",
       "             '▁asymptotic': 385,\n",
       "             '▁classifiers': 386,\n",
       "             '▁face': 387,\n",
       "             '▁kernels': 388,\n",
       "             '▁physics': 389,\n",
       "             '▁shape': 390,\n",
       "             '▁solitons': 391,\n",
       "             '▁weighted': 392,\n",
       "             '▁cnn': 393,\n",
       "             '▁distributions': 394,\n",
       "             '▁similarity': 395,\n",
       "             '▁traffic': 396,\n",
       "             'medical': 397,\n",
       "             'r': 398,\n",
       "             '▁distance': 399,\n",
       "             '▁exploration': 400,\n",
       "             '▁markov': 401,\n",
       "             '▁review': 402,\n",
       "             '▁sub': 403,\n",
       "             '▁variable': 404,\n",
       "             'regularized': 405,\n",
       "             '▁decomposition': 406,\n",
       "             '▁rank': 407,\n",
       "             '▁sample': 408,\n",
       "             '▁states': 409,\n",
       "             '▁weight': 410,\n",
       "             '▁--': 411,\n",
       "             '▁autonomous': 412,\n",
       "             '▁block': 413,\n",
       "             '▁class': 414,\n",
       "             '▁detect': 415,\n",
       "             'ity': 416,\n",
       "             '▁n': 417,\n",
       "             '▁noisy': 418,\n",
       "             '▁geometric': 419,\n",
       "             '▁open': 420,\n",
       "             '▁spin': 421,\n",
       "             '▁bi': 422,\n",
       "             '▁classifier': 423,\n",
       "             '▁constraints': 424,\n",
       "             '▁geometry': 425,\n",
       "             '▁source': 426,\n",
       "             '▁vectors': 427,\n",
       "             '▁activation': 428,\n",
       "             '▁mixture': 429,\n",
       "             '▁structural': 430,\n",
       "             '▁diffusion': 431,\n",
       "             '▁quantization': 432,\n",
       "             'rank': 433,\n",
       "             '▁estimates': 434,\n",
       "             '▁event': 435,\n",
       "             '▁scheme': 436,\n",
       "             '▁effect': 437,\n",
       "             '▁constrain': 438,\n",
       "             '▁edge': 439,\n",
       "             '▁effects': 440,\n",
       "             '▁matching': 441,\n",
       "             '▁svm': 442,\n",
       "             '$-': 443,\n",
       "             '▁auto': 444,\n",
       "             '▁co': 445,\n",
       "             '▁q': 446,\n",
       "             '▁variance': 447,\n",
       "             'ness': 448,\n",
       "             '▁ricci': 449,\n",
       "             '▁sentiment': 450,\n",
       "             '▁surface': 451,\n",
       "             '▁computational': 452,\n",
       "             '▁programming': 453,\n",
       "             '▁transport': 454,\n",
       "             '▁autoencoders': 455,\n",
       "             '▁disease': 456,\n",
       "             '▁localization': 457,\n",
       "             '▁spatio': 458,\n",
       "             'm': 459,\n",
       "             'type': 460,\n",
       "             '▁boosting': 461,\n",
       "             '▁boundary': 462,\n",
       "             '▁groups': 463,\n",
       "             '▁ii': 464,\n",
       "             '▁learned': 465,\n",
       "             '▁optimiz': 466,\n",
       "             '▁set': 467,\n",
       "             '▁signals': 468,\n",
       "             'k': 469,\n",
       "             '▁exact': 470,\n",
       "             '▁propagation': 471,\n",
       "             '▁rnn': 472,\n",
       "             '▁accurate': 473,\n",
       "             '▁multimodal': 474,\n",
       "             '▁smooth': 475,\n",
       "             '▁tasks': 476,\n",
       "             '▁topological': 477,\n",
       "             'agent': 478,\n",
       "             'g': 479,\n",
       "             'resolution': 480,\n",
       "             '▁estimate': 481,\n",
       "             '▁implicit': 482,\n",
       "             '▁sgd': 483,\n",
       "             '▁autoencoder': 484,\n",
       "             '▁black': 485,\n",
       "             '▁entropy': 486,\n",
       "             '▁least': 487,\n",
       "             '▁pattern': 488,\n",
       "             '$': 489,\n",
       "             '▁dimensional': 490,\n",
       "             '▁games': 491,\n",
       "             '▁quasi': 492,\n",
       "             '▁scaling': 493,\n",
       "             '▁synthesis': 494,\n",
       "             '▁dimension': 495,\n",
       "             '▁condition': 496,\n",
       "             '▁projection': 497,\n",
       "             '▁simulation': 498,\n",
       "             '▁$\\\\': 499,\n",
       "             '▁beyond': 500,\n",
       "             '▁hidden': 501,\n",
       "             '▁incremental': 502,\n",
       "             '▁sparsity': 503,\n",
       "             '▁temperature': 504,\n",
       "             '▁what': 505,\n",
       "             '▁backpropagation': 506,\n",
       "             '▁discovery': 507,\n",
       "             '▁partial': 508,\n",
       "             '▁rates': 509,\n",
       "             'class': 510,\n",
       "             'er': 511,\n",
       "             '▁document': 512,\n",
       "             '▁examples': 513,\n",
       "             '▁fusion': 514,\n",
       "             '▁patterns': 515,\n",
       "             'in': 516,\n",
       "             '▁combin': 517,\n",
       "             '▁component': 518,\n",
       "             '▁emotion': 519,\n",
       "             '▁mobile': 520,\n",
       "             '▁anomaly': 521,\n",
       "             '▁big': 522,\n",
       "             '▁boltzmann': 523,\n",
       "             '▁cancer': 524,\n",
       "             '▁maps': 525,\n",
       "             '▁optical': 526,\n",
       "             '▁results': 527,\n",
       "             '▁sets': 528,\n",
       "             'l': 529,\n",
       "             'é': 530,\n",
       "             '▁channel': 531,\n",
       "             '▁federated': 532,\n",
       "             '▁massive': 533,\n",
       "             '▁recommendation': 534,\n",
       "             '▁curvature': 535,\n",
       "             '▁path': 536,\n",
       "             '▁product': 537,\n",
       "             '▁three': 538,\n",
       "             '▁unified': 539,\n",
       "             'accelerating': 540,\n",
       "             '▁code': 541,\n",
       "             '▁near': 542,\n",
       "             '▁subspace': 543,\n",
       "             'o': 544,\n",
       "             '▁acceleration': 545,\n",
       "             '▁building': 546,\n",
       "             '▁datasets': 547,\n",
       "             '▁few': 548,\n",
       "             '▁modelling': 549,\n",
       "             '▁quality': 550,\n",
       "             'ireless': 551,\n",
       "             '▁can': 552,\n",
       "             '▁cluster': 553,\n",
       "             '▁diagnosis': 554,\n",
       "             '▁driven': 555,\n",
       "             '▁implementation': 556,\n",
       "             '▁matrices': 557,\n",
       "             '▁nets': 558,\n",
       "             '▁numerical': 559,\n",
       "             '▁or': 560,\n",
       "             '▁stellar': 561,\n",
       "             '▁better': 562,\n",
       "             '▁denoising': 563,\n",
       "             '▁early': 564,\n",
       "             '▁value': 565,\n",
       "             '▁bias': 566,\n",
       "             '▁label': 567,\n",
       "             '▁maximum': 568,\n",
       "             '▁molecular': 569,\n",
       "             '▁sequences': 570,\n",
       "             'ability': 571,\n",
       "             'ero': 572,\n",
       "             'label': 573,\n",
       "             'of': 574,\n",
       "             '▁compressed': 575,\n",
       "             '▁discriminative': 576,\n",
       "             '▁mapping': 577,\n",
       "             '▁use': 578,\n",
       "             '▁verification': 579,\n",
       "             '▁collaborative': 580,\n",
       "             '▁explor': 581,\n",
       "             '▁free': 582,\n",
       "             '▁dataset': 583,\n",
       "             '▁depth': 584,\n",
       "             '▁eeg': 585,\n",
       "             '▁extreme': 586,\n",
       "             '▁feedback': 587,\n",
       "             '▁improve': 588,\n",
       "             '▁orthogonal': 589,\n",
       "             '▁randomized': 590,\n",
       "             '▁resource': 591,\n",
       "             '▁user': 592,\n",
       "             'ive': 593,\n",
       "             '▁augmentation': 594,\n",
       "             '▁batch': 595,\n",
       "             '▁cloud': 596,\n",
       "             '▁computer': 597,\n",
       "             '▁exploit': 598,\n",
       "             '▁exponential': 599,\n",
       "             '▁gated': 600,\n",
       "             '▁into': 601,\n",
       "             '▁separation': 602,\n",
       "             'dependent': 603,\n",
       "             '▁completion': 604,\n",
       "             '▁ensembles': 605,\n",
       "             '▁heat': 606,\n",
       "             '▁points': 607,\n",
       "             '▁sentence': 608,\n",
       "             '▁trees': 609,\n",
       "             '▁accuracy': 610,\n",
       "             '▁character': 611,\n",
       "             '▁contextual': 612,\n",
       "             '▁dictionary': 613,\n",
       "             '▁interaction': 614,\n",
       "             '▁lattice': 615,\n",
       "             '▁mixed': 616,\n",
       "             '▁pre': 617,\n",
       "             '▁question': 618,\n",
       "             '▁some': 619,\n",
       "             '▁units': 620,\n",
       "             '▁compact': 621,\n",
       "             '▁driving': 622,\n",
       "             '▁guarantee': 623,\n",
       "             '▁intelligence': 624,\n",
       "             '▁level': 625,\n",
       "             '▁manifolds': 626,\n",
       "             '▁particle': 627,\n",
       "             '▁quadratic': 628,\n",
       "             '▁speaker': 629,\n",
       "             '▁transition': 630,\n",
       "             '▁correlation': 631,\n",
       "             '▁elliptic': 632,\n",
       "             '▁filtering': 633,\n",
       "             '▁neurons': 634,\n",
       "             '▁radial': 635,\n",
       "             '▁symmetric': 636,\n",
       "             'eterogeneous': 637,\n",
       "             'like': 638,\n",
       "             '▁benchmark': 639,\n",
       "             '▁cost': 640,\n",
       "             '▁environments': 641,\n",
       "             '▁faster': 642,\n",
       "             '▁integrat': 643,\n",
       "             '▁software': 644,\n",
       "             '▁strong': 645,\n",
       "             '▁alignment': 646,\n",
       "             '▁clinical': 647,\n",
       "             '▁dense': 648,\n",
       "             '▁layers': 649,\n",
       "             '▁monte': 650,\n",
       "             '▁positive': 651,\n",
       "             '▁recurrence': 652,\n",
       "             '▁wave': 653,\n",
       "             '▁x': 654,\n",
       "             '▁2': 655,\n",
       "             '▁decoding': 656,\n",
       "             '▁galaxy': 657,\n",
       "             '▁input': 658,\n",
       "             '▁parameters': 659,\n",
       "             '▁population': 660,\n",
       "             '▁second': 661,\n",
       "             '▁theorem': 662,\n",
       "             'i': 663,\n",
       "             'ical': 664,\n",
       "             'ion': 665,\n",
       "             '▁comparative': 666,\n",
       "             '▁continual': 667,\n",
       "             '▁direct': 668,\n",
       "             '▁factor': 669,\n",
       "             '▁imitation': 670,\n",
       "             '▁o': 671,\n",
       "             '▁part': 672,\n",
       "             '▁reasoning': 673,\n",
       "             '▁scene': 674,\n",
       "             '▁sound': 675,\n",
       "             '▁topology': 676,\n",
       "             '▁vision': 677,\n",
       "             '▁asynchronous': 678,\n",
       "             '▁decentraliz': 679,\n",
       "             '▁differentiable': 680,\n",
       "             '▁enhanced': 681,\n",
       "             '▁hardware': 682,\n",
       "             '▁higher': 683,\n",
       "             '▁mirror': 684,\n",
       "             '▁policies': 685,\n",
       "             '▁predictions': 686,\n",
       "             '▁ranking': 687,\n",
       "             '▁target': 688,\n",
       "             '▁transform': 689,\n",
       "             'layer': 690,\n",
       "             '▁approaches': 691,\n",
       "             '▁attack': 692,\n",
       "             '▁generat': 693,\n",
       "             '▁line': 694,\n",
       "             '▁mass': 695,\n",
       "             '▁multivariate': 696,\n",
       "             '▁not': 697,\n",
       "             '▁polynomial': 698,\n",
       "             '▁polynomials': 699,\n",
       "             '▁sensor': 700,\n",
       "             '▁statistics': 701,\n",
       "             'or': 702,\n",
       "             'view': 703,\n",
       "             '▁interactions': 704,\n",
       "             '▁operator': 705,\n",
       "             '▁permutations': 706,\n",
       "             '▁platform': 707,\n",
       "             '▁potential': 708,\n",
       "             '▁prior': 709,\n",
       "             '▁private': 710,\n",
       "             '▁riemannian': 711,\n",
       "             '▁solution': 712,\n",
       "             '▁testing': 713,\n",
       "             '▁critical': 714,\n",
       "             '▁library': 715,\n",
       "             '▁logic': 716,\n",
       "             '▁measures': 717,\n",
       "             '▁normalization': 718,\n",
       "             '▁operators': 719,\n",
       "             '▁planning': 720,\n",
       "             '▁pruning': 721,\n",
       "             '\"': 722,\n",
       "             'b': 723,\n",
       "             '▁\"': 724,\n",
       "             '▁carlo': 725,\n",
       "             '▁instance': 726,\n",
       "             '▁pose': 727,\n",
       "             '▁region': 728,\n",
       "             '▁stable': 729,\n",
       "             '▁unit': 730,\n",
       "             '▁weak': 731,\n",
       "             '▁weakly': 732,\n",
       "             'ell': 733,\n",
       "             '▁encoding': 734,\n",
       "             '▁galact': 735,\n",
       "             '▁interpretation': 736,\n",
       "             '▁mimo': 737,\n",
       "             '▁size': 738,\n",
       "             '▁strategies': 739,\n",
       "             '▁analytics': 740,\n",
       "             '▁do': 741,\n",
       "             '▁entity': 742,\n",
       "             '▁feedforward': 743,\n",
       "             '▁inter': 744,\n",
       "             '▁invariant': 745,\n",
       "             '▁mri': 746,\n",
       "             '▁protein': 747,\n",
       "             '▁rule': 748,\n",
       "             '▁color': 749,\n",
       "             '▁composite': 750,\n",
       "             '▁double': 751,\n",
       "             '▁filter': 752,\n",
       "             '▁media': 753,\n",
       "             '▁mining': 754,\n",
       "             'f': 755,\n",
       "             '▁dropout': 756,\n",
       "             '▁formation': 757,\n",
       "             '▁norm': 758,\n",
       "             '▁practical': 759,\n",
       "             '▁shallow': 760,\n",
       "             '▁their': 761,\n",
       "             '▁weights': 762,\n",
       "             'box': 763,\n",
       "             'x': 764,\n",
       "             '▁acoustic': 765,\n",
       "             '▁algebraic': 766,\n",
       "             '▁all': 767,\n",
       "             '▁approximations': 768,\n",
       "             '▁challenges': 769,\n",
       "             '▁coupled': 770,\n",
       "             '▁g': 771,\n",
       "             '▁hashing': 772,\n",
       "             '▁monitoring': 773,\n",
       "             '▁star': 774,\n",
       "             '▁when': 775,\n",
       "             '+': 776,\n",
       "             'field': 777,\n",
       "             'ization': 778,\n",
       "             'modal': 779,\n",
       "             'smooth': 780,\n",
       "             '▁devices': 781,\n",
       "             '▁fine': 782,\n",
       "             '▁light': 783,\n",
       "             '▁mechanism': 784,\n",
       "             '▁more': 785,\n",
       "             '▁relations': 786,\n",
       "             '▁term': 787,\n",
       "             '▁theoretical': 788,\n",
       "             '▁view': 789,\n",
       "             'domain': 790,\n",
       "             '▁capacity': 791,\n",
       "             '▁future': 792,\n",
       "             '▁impact': 793,\n",
       "             '▁management': 794,\n",
       "             '▁many': 795,\n",
       "             '▁margin': 796,\n",
       "             '▁pair': 797,\n",
       "             '▁radio': 798,\n",
       "             '▁relu': 799,\n",
       "             '▁response': 800,\n",
       "             '▁train': 801,\n",
       "             '▁variables': 802,\n",
       "             '▁virtual': 803,\n",
       "             '▁assessment': 804,\n",
       "             '▁causal': 805,\n",
       "             '▁cnns': 806,\n",
       "             '▁codes': 807,\n",
       "             '▁curves': 808,\n",
       "             '▁dialogue': 809,\n",
       "             '▁importance': 810,\n",
       "             '▁map': 811,\n",
       "             '▁measurements': 812,\n",
       "             '▁recursive': 813,\n",
       "             '▁rules': 814,\n",
       "             '▁spectrum': 815,\n",
       "             '▁spike': 816,\n",
       "             '▁surfaces': 817,\n",
       "             'trained': 818,\n",
       "             '▁conjugate': 819,\n",
       "             '▁evaluating': 820,\n",
       "             '▁infinite': 821,\n",
       "             '▁no': 822,\n",
       "             '▁objects': 823,\n",
       "             'restricted': 824,\n",
       "             '▁abundance': 825,\n",
       "             '▁aggregation': 826,\n",
       "             '▁chemical': 827,\n",
       "             '▁concept': 828,\n",
       "             '▁faci': 829,\n",
       "             '▁health': 830,\n",
       "             '▁hyper': 831,\n",
       "             '▁physical': 832,\n",
       "             '▁sum': 833,\n",
       "             '▁that': 834,\n",
       "             '(': 835,\n",
       "             '▁connections': 836,\n",
       "             '▁deterministic': 837,\n",
       "             '▁different': 838,\n",
       "             '▁lasso': 839,\n",
       "             '▁measure': 840,\n",
       "             '▁priors': 841,\n",
       "             '▁soft': 842,\n",
       "             '▁videos': 843,\n",
       "             '▁wasserstein': 844,\n",
       "             '▁ct': 845,\n",
       "             '▁distillation': 846,\n",
       "             '▁estimat': 847,\n",
       "             '▁fixed': 848,\n",
       "             '▁forward': 849,\n",
       "             '▁genetic': 850,\n",
       "             '▁guid': 851,\n",
       "             '▁nonparametric': 852,\n",
       "             '▁primal': 853,\n",
       "             '▁probability': 854,\n",
       "             '▁role': 855,\n",
       "             '▁steepest': 856,\n",
       "             '▁topic': 857,\n",
       "             '▁we': 858,\n",
       "             'ized': 859,\n",
       "             'less': 860,\n",
       "             '▁ai': 861,\n",
       "             '▁back': 862,\n",
       "             '▁compositional': 863,\n",
       "             '▁compressive': 864,\n",
       "             '▁content': 865,\n",
       "             '▁gas': 866,\n",
       "             '▁interactive': 867,\n",
       "             '▁resolution': 868,\n",
       "             'and': 869,\n",
       "             '▁bidirectional': 870,\n",
       "             '▁dimensionality': 871,\n",
       "             '▁encoder': 872,\n",
       "             '▁events': 873,\n",
       "             '▁game': 874,\n",
       "             '▁number': 875,\n",
       "             '▁parsing': 876,\n",
       "             '▁research': 877,\n",
       "             '▁thermal': 878,\n",
       "             'characterization': 879,\n",
       "             'ognitive': 880,\n",
       "             'ry': 881,\n",
       "             '▁classical': 882,\n",
       "             '▁construction': 883,\n",
       "             '▁embedded': 884,\n",
       "             '▁environment': 885,\n",
       "             '▁expansion': 886,\n",
       "             '▁multitask': 887,\n",
       "             '▁rnns': 888,\n",
       "             '▁streaming': 889,\n",
       "             '▁tool': 890,\n",
       "             '▁velocity': 891,\n",
       "             'st': 892,\n",
       "             'state': 893,\n",
       "             '▁agents': 894,\n",
       "             '▁answering': 895,\n",
       "             '▁electric': 896,\n",
       "             '▁electron': 897,\n",
       "             '▁hyperparameter': 898,\n",
       "             '▁initialization': 899,\n",
       "             '▁micro': 900,\n",
       "             '▁newton': 901,\n",
       "             '▁robot': 902,\n",
       "             '▁spatially': 903,\n",
       "             '▁squares': 904,\n",
       "             '▁step': 905,\n",
       "             '▁stock': 906,\n",
       "             '▁u': 907,\n",
       "             '▁ultra': 908,\n",
       "             'interpretability': 909,\n",
       "             'network': 910,\n",
       "             '▁bandit': 911,\n",
       "             '▁bandits': 912,\n",
       "             '▁combinatorial': 913,\n",
       "             '▁connected': 914,\n",
       "             '▁disk': 915,\n",
       "             '▁efficiency': 916,\n",
       "             '▁electronic': 917,\n",
       "             '▁finding': 918,\n",
       "             '▁gravity': 919,\n",
       "             '▁labels': 920,\n",
       "             '▁minimum': 921,\n",
       "             '▁momentum': 922,\n",
       "             '▁pca': 923,\n",
       "             '▁person': 924,\n",
       "             '▁plasticity': 925,\n",
       "             '▁principal': 926,\n",
       "             '▁programs': 927,\n",
       "             '▁samples': 928,\n",
       "             '▁security': 929,\n",
       "             '▁smart': 930,\n",
       "             '▁solar': 931,\n",
       "             'oriented': 932,\n",
       "             're': 933,\n",
       "             '{': 934,\n",
       "             '▁across': 935,\n",
       "             '▁be': 936,\n",
       "             '▁bounds': 937,\n",
       "             '▁classifying': 938,\n",
       "             '▁enhancement': 939,\n",
       "             '▁forest': 940,\n",
       "             '▁mechanics': 941,\n",
       "             '▁minimal': 942,\n",
       "             '▁note': 943,\n",
       "             '▁optimality': 944,\n",
       "             '▁overview': 945,\n",
       "             '▁property': 946,\n",
       "             '▁singular': 947,\n",
       "             '▁speed': 948,\n",
       "             '▁stars': 949,\n",
       "             '▁tomography': 950,\n",
       "             '▁variation': 951,\n",
       "             '&': 952,\n",
       "             'ray': 953,\n",
       "             'world': 954,\n",
       "             '▁count': 955,\n",
       "             '▁development': 956,\n",
       "             '▁identifying': 957,\n",
       "             '▁inequalities': 958,\n",
       "             '▁labeling': 959,\n",
       "             '▁likelihood': 960,\n",
       "             '▁reduced': 961,\n",
       "             '▁simulations': 962,\n",
       "             '▁up': 963,\n",
       "             'omorphic': 964,\n",
       "             '▁alternating': 965,\n",
       "             '▁analyzing': 966,\n",
       "             '▁chain': 967,\n",
       "             '▁explain': 968,\n",
       "             '▁lower': 969,\n",
       "             '▁market': 970,\n",
       "             '▁modified': 971,\n",
       "             '▁modular': 972,\n",
       "             '▁multilayer': 973,\n",
       "             '▁observations': 974,\n",
       "             '▁off': 975,\n",
       "             '▁waves': 976,\n",
       "             'channel': 977,\n",
       "             'point': 978,\n",
       "             '▁arbitrary': 979,\n",
       "             '▁cell': 980,\n",
       "             '▁composition': 981,\n",
       "             '▁constraint': 982,\n",
       "             '▁covariance': 983,\n",
       "             '▁flexibl': 984,\n",
       "             '▁fourier': 985,\n",
       "             '▁gan': 986,\n",
       "             '▁intrinsic': 987,\n",
       "             '▁precision': 988,\n",
       "             '▁rotation': 989,\n",
       "             '▁synchronization': 990,\n",
       "             '▁trajectory': 991,\n",
       "             'dual': 992,\n",
       "             'ng': 993,\n",
       "             'the': 994,\n",
       "             'ö': 995,\n",
       "             '▁algebra': 996,\n",
       "             '▁belief': 997,\n",
       "             '▁controll': 998,\n",
       "             '▁correction': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TGT.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "colab_type": "code",
    "id": "bnaHmrYPooZW",
    "outputId": "8d36242a-3ad7-453e-938b-72a9546c608e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2892,    10,    32,  ...,    27,    10,     8],\n",
      "        [    4,    17,   258,  ...,   481,    17,   148],\n",
      "        [   16,   980,    19,  ...,  2352,   980,   140],\n",
      "        ...,\n",
      "        [  254,   886,   284,  ...,     1,     1,     1],\n",
      "        [  271,   802, 12142,  ...,     1,     1,     1],\n",
      "        [    3,     3,     1,  ...,     1,     1,     1]])\n",
      "tensor([[  804,    13,    17,   671,     7,   243,     9, 11046,    26,     7,\n",
      "          6307,   998, 16696,    62,   117,     8],\n",
      "        [    4,   151,    82,  2735,    19,   935,   277,    10,   110,    19,\n",
      "           211,    23,   265,     2,  1509,    27],\n",
      "        [ 2059,   544,  2034,  1982,    65,    62,  1526, 10759,   393,  1198,\n",
      "          6366,  1226,     6,   236,    50,   669],\n",
      "        [ 1601,   835,   617,   554,    50,   193,    19,   116,    39,   389,\n",
      "           203,    11, 15019,   600,  3239,    36],\n",
      "        [   94,   240,     2,    10,    47,  3643,    14,    15,     8,    37,\n",
      "          7048,   688,    11,    27,   409,    11],\n",
      "        [  517,  1727,  1736,  3162,    33,    25, 13855,  7383,   237,     3,\n",
      "            47,    23,    55,   730,    11,   363],\n",
      "        [   23,    36,    14,  1109,     9,    27,  2909,    17,     5,    56,\n",
      "            25,  8061,   531,    12,   151,    52],\n",
      "        [  169,    18,   190,   150,   842,     7,   835,     2,     3,    14,\n",
      "             9,     6,   886,     3,    60,     2],\n",
      "        [    4,     9,    31,    25,     2,    12,   240,    13, 14319,  1173,\n",
      "          1440,  7500,    31,  1367, 11095,   353],\n",
      "        [  192,    73,   484,     9,   573,    18,  1727,  6220,    28,  1261,\n",
      "             4, 13193,  3143,   451,   258,     6],\n",
      "        [    7,   451,    31,     8,    31,   463,    97,   692,    11,    87,\n",
      "           390,   925,     2,  3948, 11206,    62],\n",
      "        [   12,    11,     6,     5,   205,     4,   272,    17,  1868,    11,\n",
      "             2,  1255, 13020,    51,  1727,     2],\n",
      "        [   31,   714,   565,    11,   285,  3482,     6,  1136,    16,   120,\n",
      "            34,     3,     2,    17,   560,  1311],\n",
      "        [  850,   607,  1280,   691,     2,   193,   101,     8,    53,    21,\n",
      "           134,   129, 11831,    32,   151,    26],\n",
      "        [   15,     6,     3,    31,  1542,    11,    21,     5,    29,  8034,\n",
      "             6,   208,  2683,  2474,   214,     2],\n",
      "        [   64,    66,     8,  1427,   423,     9,  1275,   101,    93,   398,\n",
      "            93,  1153,    23,    29,  1150,  4125],\n",
      "        [    6,   278,    42,     6,     1,   169,   980,     1,  6739,     2,\n",
      "          3091,     5,  1641,     1,   383,    36],\n",
      "        [   80,  1199,     5,   182,     1,    46,   656,     1,    17,   383,\n",
      "          1251,    10,   413,     1, 11093,     1],\n",
      "        [ 2150,     1,     1,   253,     1,     1,     1,     1,    32,   433,\n",
      "            15,   284,     1,     1,  8219,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     1,     1,   138,   784,\n",
      "            75,     7,     1,     1,     1,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     1,     1,  2098,     1,\n",
      "             1,    12,     1,     1,     1,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     1,     1,   215,     1,\n",
      "             1,     1,     1,     1,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "for batch in train_iter:\n",
    "    break\n",
    "print(batch.src)\n",
    "print(batch.tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "6clbILpwooZe",
    "outputId": "f233fa67-3f63-405e-cc45-b9effde702e6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([253, 16])\n",
      "torch.Size([15, 16])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    break\n",
    "small_tgt = batch.tgt\n",
    "small_src = batch.src\n",
    "print(small_src.shape)\n",
    "print(small_tgt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "V13xbMeZdWYY",
    "outputId": "f9b1162b-d954-4c80-bb8f-99194c9c5353"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 966, 1442, 1408,    8, 9788,  182,  252, 1297, 4287,  714,   55,  127,\n",
       "           9, 1236,   44,  100])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_tgt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7nQbRsxyooZp"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim: int,\n",
    "                 emb_dim: int, \n",
    "                 hid_dim: int, \n",
    "                 n_layers:int, \n",
    "                 dropout:float):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,\n",
    "                src: Tensor) -> Tuple[Tensor]:\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hx, cx) = self.rnn(embedded)\n",
    "        return hx, cx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_0oOKFnooZz"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_dim: int,\n",
    "                 emb_dim: int,\n",
    "                 hid_dim: int,\n",
    "                 n_layers: int,\n",
    "                 dropout: float):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.linear_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, \n",
    "                hx: Tensor,\n",
    "                cx: Tensor):\n",
    "        x = x.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, (hx, cx) = self.rnn(embedded, (hx, cx))\n",
    "        prediction = self.linear_out(output.squeeze(0))\n",
    "        return prediction, hx, cx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJf3WxtlooZ9"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, \n",
    "                 encoder: nn.Module,\n",
    "                 decoder: nn.Module,\n",
    "                 device: torch.device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim\n",
    "        assert encoder.n_layers == encoder.n_layers\n",
    "    \n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                tgt: Tensor, \n",
    "                teacher_forcing_ratio: float = .5) -> Tensor:\n",
    "        batch_size = tgt.shape[1]\n",
    "        tgt_len = tgt.shape[0]\n",
    "        tgt_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        outputs = torch.zeros(tgt_len, batch_size, tgt_vocab_size).to(self.device)\n",
    "        hx, cx = self.encoder(src)\n",
    "        inp = tgt[0,:]\n",
    "        for t in range(1, tgt_len):\n",
    "            output, hx, cx = self.decoder(inp, hx, cx)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            inp = tgt[t] if teacher_force else top1\n",
    "        return outputs\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Bmk8ojhooaG"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TGT.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "qpZPwhP3ooaP",
    "outputId": "c78bcf9e-e001-4e7a-b902-499855239fe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(41855, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(17770, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (linear_out): Linear(in_features=512, out_features=17770, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m: nn.Module):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dka_ZwXjooaX",
    "outputId": "c74b004d-a576-47b3-a244-cb6bd7e4bcc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 31,736,426 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ghYcb4D2ooai"
   },
   "outputs": [],
   "source": [
    "PAD_IDX = TGT.vocab.stoi[TGT.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJ2OEE6kooas"
   },
   "outputs": [],
   "source": [
    "def train(model: nn.Module,\n",
    "          iterator: data.BucketIterator,\n",
    "          optimizer, criterion,\n",
    "          clip: float):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        tgt = batch.tgt\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt)\n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        tgt = tgt[1:].view(-1)\n",
    "        \n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip) \n",
    "        # clip the gradients to prevent form them from exploding\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator) # averaged over all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xE9VXoZ2ooa0"
   },
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module,\n",
    "             iterator: data.BucketIterator,\n",
    "             criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            tgt = batch.tgt\n",
    "            output = model(src, tgt, 0) # trun off teacher forcing\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            tgt = tgt[1:].view(-1)\n",
    "            loss = criterion(output, tgt)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8ii3_9Sooa7"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kS-ZK35aoobC"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "colab_type": "code",
    "id": "wJZhP7TGoobK",
    "outputId": "17f22189-76ef-4059-c069-253693d062dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 173m 46s\n",
      "\tTrain Loss: 6.600 | Train PPL: 735.263\n",
      "\t Val. Loss: 6.730 |  Val. PPL: 837.055\n",
      "Epoch: 02 | Time: 175m 12s\n",
      "\tTrain Loss: 5.998 | Train PPL: 402.726\n",
      "\t Val. Loss: 6.581 |  Val. PPL: 721.138\n",
      "Epoch: 03 | Time: 174m 40s\n",
      "\tTrain Loss: 5.684 | Train PPL: 294.190\n",
      "\t Val. Loss: 6.451 |  Val. PPL: 633.074\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 3\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iter, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "23dWNIF_RESo",
    "outputId": "07de9fb1-4bab-49ef-b1b8-2bf069899a27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 6.479 | Test PPL: 651.592 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iter, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMADqyqkPPhA"
   },
   "outputs": [],
   "source": [
    "def sample(abstract: str,\n",
    "           title_len: int):\n",
    "    sample_src = SRC.process([abstract])\n",
    "    model.eval()\n",
    "    init_tgt = torch.zeros([title_len,1], dtype = torch.int64, device = device)\n",
    "    with torch.no_grad():\n",
    "        output = model(sample_src, init_tgt,0)\n",
    "#         output = output[1:].view(-1, output.shape[-1])\n",
    "#         tgt = init_tgt[1:].view(-1)\n",
    "#         loss = criterion(output, tgt)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones([15,1], dtype = torch.int64, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "InYB6xvuPG7W"
   },
   "outputs": [],
   "source": [
    "abstract = \"The notion of approachability in repeated games with vector payoffs was introduced by Blackwell in the 1950s, along with geometric conditions for approachability and corresponding strategies that rely on computing {\\\\em steering directions} as projections from the current average payoff vector to the (convex) target set. Recently, Abernethy, Batlett and Hazan (2011) proposed a class of approachability algorithms that rely on the no-regret properties of Online Linear Programming for computing a suitable sequence of steering directions. This is first carried out for target sets that are convex cones, and then generalized to any convex set by embedding it in a higher-dimensional convex cone. In this paper we present a more direct formulation that relies on the support function of the set, along with suitable Online Convex Optimization algorithms, which leads to a general class of approachability algorithms. We further show that Blackwell's original algorithm and its convergence follow as a special case.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "V2QnpYdAeNER",
    "outputId": "6c6519c1-5c04-459d-fdbb-bf5ad65a179d"
   },
   "outputs": [],
   "source": [
    "sample_emb = sample(abstract, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
       "\n",
       "        [[-10.2533, -10.5065,   4.9751,  ...,  -8.1297,  -7.0462, -10.5310]],\n",
       "\n",
       "        [[ -8.5878,  -8.5561,   3.1518,  ...,  -5.4253,  -3.1851,  -8.8318]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ -8.9973,  -8.8578,   4.2204,  ...,  -7.3072,  -5.8002,  -8.9551]],\n",
       "\n",
       "        [[ -8.0867,  -7.9898,   3.6826,  ...,  -6.9334,  -4.9049,  -7.9369]],\n",
       "\n",
       "        [[ -7.3639,  -7.3315,   3.4692,  ...,  -6.6031,  -4.5958,  -7.2013]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-89bb4a06b077>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0musetgtvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mTGT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_idxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-60-89bb4a06b077>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0musetgtvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mTGT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_idxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "usetgtvocab = [TGT.vocab.itos[idx] for idx in sample_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usetgtvocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJyyNq_Lgaxk"
   },
   "outputs": [],
   "source": [
    "https://github.com/pytorch/text/issues/346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9qI9BT5Ogauv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWVlFKq6garX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zHPMJbvgaoz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q3BF-QreeBao"
   },
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module,\n",
    "             iterator: data.BucketIterator,\n",
    "             criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            tgt = batch.tgt\n",
    "            output = model(src, tgt, 0) # trun off teacher forcing\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            tgt = tgt[1:].view(-1)\n",
    "            loss = criterion(output, tgt)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E0TOVlfHoobd"
   },
   "outputs": [],
   "source": [
    "def sample(data_loader, net, prime, sex, origin):\n",
    "\n",
    "    origin_tensor = data_loader.ORIGIN.process([origin]).float().to(device)\n",
    "    sex_tensor = data_loader.SEX.process([sex]).float().to(device)\n",
    "\n",
    "    prime = prime.lower()\n",
    "    prime_tensor = data_loader.BABYNAME.process([prime])[:, :-1].to(device)\n",
    "    bsz, prime_tensor_length = prime_tensor.size()\n",
    "\n",
    "    # 인풋을 모델에 넣어 출력합니다.\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        # batch_size = 1\n",
    "        hidden = net.init_hidden(1)\n",
    "\n",
    "        for step in range(prime_tensor_length):\n",
    "            with torch.no_grad():\n",
    "                predication, hx, cx = net(encoder, )\n",
    "            probabilities = F.softmax(outputs, 1)\n",
    "\n",
    "    return probabilities.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8WxD795oobj"
   },
   "outputs": [],
   "source": [
    "tensor([   5,  425,    9,    5, 1629, 2202,   52,   38,   18,   13,  145, 9863,\n",
    "         179,   18,  125,   13], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "GyRhYXKAoobp",
    "outputId": "949f4e9c-053f-42a5-99af-be25d8891960"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones([15,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LS8Oej0goob0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wus32pTcoob9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YZO44yg-oocI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lcaU9lZ0oocN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRUiz5l8oocU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4g8_9G6Noocg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "seq2seq_TitleGenerator_TEST4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
